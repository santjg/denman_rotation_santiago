{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stimulus Paradigms\n",
    "* **Montijin et al., 2015**  \n",
    "    * Calcium imaging of V1 L2/L3 using two photon\n",
    "    * Thin film transistor screen (TFT)\n",
    "        * 60Hz refresh rate positioned at 16cm from mouse eye\n",
    "    * Sequences of eight different directions of square-wave drifting gratings that were monoculrly presented in monocularly presented in randomized order\n",
    "    * Stimulus duration started at infinite during the initial training phase and was gradually reduced to a max duration of 3s for the final task stage\n",
    "    * Stimuli alternated by blank inter-trial interval of variable duration (10-12s)\n",
    "        * Gray screen presented\n",
    "    * Visual drifting gratings presented within circular cosine-ramped window to avoid edge effects at the border of the circular window\n",
    "* **Denman and Reid., 2019**  \n",
    "    * Immersive stimulation system (ours)\n",
    "    * Achromatic settings\n",
    "    * **Stimulus sequence:**\n",
    "        * Spatiotemporal dense noise stimulus\n",
    "        * Naturalistic images\n",
    "        * Spatially uniform flicker\n",
    "        * repeated naturalistic movie\n",
    "        * Spatiotemporal dense noise stimulus (second presentation for measure of continuity)\n",
    "    * Spatially uniform luminance flcker\n",
    "        * Step changes in luminance at 20Hz\n",
    "        * 15s, repeated 40-50times\n",
    "* **Stringer et al., 2019**  \n",
    "    * V1 neural activity recording using GCaMP sensors and two-photon \n",
    "    * Natural images projected on three screen array surorunding a mouse (RGB Screens?)\n",
    "    * Average of 1 image per second\n",
    "    * 2800 image stimuli\n",
    "        * Presented twice in the same order\n",
    "        \n",
    "* **Meeting - 06/30/2020**\n",
    "    * Use Garg et al., 2019 as a model for our stimulus\n",
    "        * basic co-representation of color and shape features in mouse cortex\n",
    "        * How population activity depends on these things\n",
    "        * Blobs and interblobs in Mouse V1??\n",
    "        * M2 receptor staining defines blobs in V1\n",
    "    * Are color and shape representations connected to their position within blobs and interblobs?\n",
    "    * What we need is the ability to characterize single cells how Garg paper did\n",
    "    * Achromatic orientation tuning\n",
    "    * color opponent gratings\n",
    "    * Account for eye postion?\n",
    "    * Black-white receptve field mapping\n",
    "    * Color contrast noise\n",
    "    * Color warp?\n",
    "        * Question about the system? - Dont warp\n",
    "        * Question about V1? - Warp\n",
    "    * 90min of stimulus time\n",
    "        * achromatic and color noise (receptive field)\n",
    "        * achromatic and equiluminant color gradings\n",
    "        * black and white and color gradings with orientation\n",
    "        * simple color tuning (flashes?)\n",
    "        * Color exchange stimulus? or simple steps? (JNeuro Paper)\n",
    "        * Static images (naturalistic, fixed order w/ and w/o color, shuffled)\n",
    "    * Folow up experiments would target V1 more than the system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions/Comments for Dan\n",
    "* Send me papers where RGB stimuli were used for mouse visual experiments  \n",
    "    * Better understand the failures\n",
    "* *Touch of Evil* (1958)??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes from Dan\n",
    "* The most important aspect of our stimulus wrt our question is the wavelength.\n",
    "    * 530nm only\n",
    "    * 380nm only\n",
    "    * both - high luminance\n",
    "    * both - low luminance\n",
    "* What activity are we measuring?\n",
    "    * We should choose stimuli for which we have something to measure\n",
    "    * Receptive fields\n",
    "    * Total spiking count\n",
    "    * What else?? - This will drive what other stimuli we choose\n",
    "* Pair thoughts about stimuli with analyses\n",
    "    * Think about what I find interesting in population analysis   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Glossary\n",
    "* **Cone Photoreceptors -** Mediate color vision\n",
    "    * concentrated in the fovea\n",
    "    * Work well only in bright light\n",
    "* **Efficient Coding Hypothesis -** Neural code maximized transmission of info by eliminating correlations in natural image inputs   \n",
    "    * High dimensional and sparse code\n",
    "    * Enable complex features to be read by siple downstream neural neworks  \n",
    "* **Fovea -** Region of highest acuity in the retina. Highest concentration of photoreceptors\n",
    "* **Gabor Filter -** linear filter used for texture analysis, which means that it basically analyzes whether there are any specific frequency content in the image in specific directions in a localized region around the point or region of analysis.  \n",
    "* **Horizontal Cells -** Mediate the size of receptive fields. \n",
    "    * Behave as though they have excitatory receptors for glutamae and make inhibitory synapses on neigboring cells in the field center\n",
    "* **Intensity -** Amplitude of light reaching the eye. Corresponds to perceptual brightness of an object\n",
    "* **Lateral Geniculate Nucleus (LGN) -** Relay center in the thalamus for the visual pathway. First synapse for retinal ganglion cell efferents.   \n",
    "* **Medium Wavelength (M) Opsin -** Sensitive to green light  \n",
    "* **Noise Correlation -** Shared response variability between neurons  \n",
    "    * **Not an instantaneous measure**  \n",
    "    * computation requires integrating neural activity over multiple timepoints or stimulus repititions  \n",
    "* **Population Code -** The pattern of activity evoked in neurons by stimuli  \n",
    "* **Primary Visual Cortex (V1) -** Posterior pole of the occipital lobe. Simplest, earliest cortical visual area. Highly specialized for processing info about static and moving objects. Excellent in pattern recognition.  \n",
    "    * Detection, discrimination, and awareness of visual stimuli   \n",
    "* **Rate-based feature encoding -** variance in spiking rate of indiidual cells relative to the stimulus\n",
    "* **Receptive Field -** the optimal stimulus to evoke a change in activity from a single sensory neuron\n",
    "    * Smaller in the fovea, larger in the periphery\n",
    "* **Reduced Rank Regression -** a multivariate regression model with a coefficient matrix with reduced rank\n",
    "    *  takes into account the reduced rank restriction on the coefficient matrix    \n",
    "* **Response heterogeneity -** Novel population metric developed by Montijin et al., 2015  \n",
    "    * Captures dissimilarity of neuronal responses in a population\n",
    "    * Correlates better with stimulus detection performance and reaction time    \n",
    "* **Retina Amacrine Cells -**  Important for creating functional subunits within the ganglion cell layer (particularly narrow field cells) so that ganglion cells can observe a small dot moving a small distance. \n",
    "* **Retinal Ganglion Cells -** Type of neuron located near the iner surface of the retina. Receives input from photoreceptors (rods, cones) via bipolar cells and retina amacrine cells. Efferents to thalamus (LGN), hypothalamus, and mesencephalon. Axons form the optic nerve, tract, etc.    \n",
    "    * Only cells that generate action potentials\n",
    "    * \"Donut-shaped\" receptive fields\n",
    "    * Two types\n",
    "        * Excited by light shining in their centers and inhibited by the periphery (\"ON\")\n",
    "        * Excited by light shining on periphery and inhibited by light shining on the center (\"OFF\")\n",
    "    * Fire spontaneously in the dark\n",
    "    * Highly responsive to both excitatory and inhibitory input\n",
    "* **Rod Photoreceptors -** Dominant photoreceptor away from the fovea\n",
    "    * color insensitive\n",
    "    * Work best in dim light\n",
    "* **Simple Nearest Neighbor Decoder -** K Nearest Neighbour is a simple algorithm that stores all the available cases and classifies the new data or case based on a similarity measure.   \n",
    "    * It is mostly used to classifies a data point based on how its neighbours are classified.  \n",
    "* **Short Wavelength (S) Opsin -** Sensitive to ultraviolet light   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes on Papers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[**Mechanisms of Orientation Selectivity in the Primary Visual Cortex**](https://www.annualreviews.org/doi/full/10.1146/annurev-vision-111815-114456?url_ver=Z39.88-2003&rfr_id=ori%3Arid%3Acrossref.org&rfr_dat=cr_pub++0pubmed) - Priebe, 2016"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[**The Machinery of Colour Vision**](https://www.nature.com/articles/nrn2094) - Solomon and Lennie, 2007    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[**A Tour of Contemporary Color Vision Research**](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6345392/) - Conway et al., 2018\n",
    "* We can predict how the three classes of cones react to a given stimulus, but how that code leads to perception of color is a mystery\n",
    "* Cone-opponency is different than color opponency\n",
    "    * Color-opponency relates to color appearance \n",
    "    * Cone opponency can occur without any color discrimination\n",
    "* Cones don't correcpond to color percepts\n",
    "* One million retinal ganglion cells per eye, comparable number in each LGN, but over 100 million cells per hemisphere in V1\n",
    "    * ~100x expansion\n",
    "* Cortical neuron that receives equal input from all three cones will respond best to achromatic input\n",
    "    * Any imbalance causes cell to respond best to specific color direction other than achromatic \n",
    "* Small fraction fo V1 cells show striking cone opponency\n",
    "* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[**The Visual System: Medical School Handout**](https://somed.ucdenver.edu/ilios/learnmat/96932/NS%2009-16-19%2010AM%20Vision%20I-II%20Handout%20-%20Poleg-Polsky.pdf) - Alon Poleg-Polsky\n",
    "* Wavelength responds to color, amplitude repsondsto intesity/brightness\n",
    "* Photoreceptors face the back of the eye (not the front) meaning light needs to pass through all of the cells before reaching photoreceptors\n",
    "* Light absorption causes photoreceptors to hyperpolarize\n",
    "    * Analogous to other GPCR systems\n",
    "* **Only the ganglion cells make action potentials**\n",
    "* ~100:1 ratio of photoreceptors to efferent axons\n",
    "* The retina is wired to detect contrast\n",
    "    * The first step in building specific detectors for edges, corners, shapes, and faces\n",
    "* In the fovea, gaglion cell receptive field may be as small as a single cone with an antagonistic surround that isnt much bigger\n",
    "* Receptive fields are larger in the periphery, smaller in the fovea\n",
    "* **Receptive field is mediated by horizontal cells**   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[**Color and orientation are jointly coded and spatially organized in the primate primary visual cortex**](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6689325/) - Garg et al., 2019  \n",
    "* Used 2-photon calcium imaging to probe very large spatial and chromatic visual stimulus space and map functional microarchitecture of thousands of neurons\n",
    "* Circularly symmetric inputs are combined to generate orientation selectivity\n",
    "* Cone opponent inputs are transformed to create color selectivity\n",
    "* How color is coded in the cortex is still a huge question in visual neuroscience\n",
    "* Prior model proposed color and orientaton were separately extracted within V1 and represented by neurons located in different cortical columns\n",
    "    * Project separately to higher visual areas for further processing\n",
    "    * Subsequent studies show no modular spatial segregation of these properties\n",
    "* Looking for neurons that are selective for orientation and color which also respond much mroe strongly to preferred color than achromatic stimuli\n",
    "* Neurons responding most strongly to specific wavelength were the least orientation-selective group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[**Do We Know What the Early Visual System Does?**](https://www.jneurosci.org/content/25/46/10577.short) - Carandini et al., 2005"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[**How close are we to understaning V1?**](http://redwood.psych.cornell.edu/papers/V1-article.pdf) - Olshausen and Field, 2005"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[**High-dimensional geometry of population responses in visual cortex**](https://www.nature.com/articles/s41586-019-1346-5) - Stringer et al., 2019\n",
    "*  Many researchers theorize \"efficient coding hypothesis\"\n",
    "*  Many studies demonstrate however that neural codes operate in lower dimensional planes\n",
    "    * Correlated and redundant code allowing for robust signals despite noise\n",
    "    * Responses to n stimuli  = n-dimensional subspace\n",
    "* Planar dimension of cortical code remains an open question until we're able to record large populations\n",
    "* **Methods**\n",
    "    * V1 neural activity recording using GCaMP sensors and two-photon \n",
    "    * Natural images projected on three screen array surorunding a mouse (RGB Screens?)\n",
    "    * Average of 1 image per second\n",
    "    * 2800 image stimuli\n",
    "        * Presented twice in the same order\n",
    "    * Receptive field calculated for each neuron in two ways\n",
    "        * Fitting linear receptive fields regularized with reduced rank method\n",
    "        * Searching for an optimal Gabor filter that was rectified to simulate simple cell responses, and quadrature filtered to simulate complex cell responses. \n",
    "* **Findings**\n",
    "    * Stimulus responses neither uncorrelated (i.e. efficient) nor low dimensional.\n",
    "    * Responses occupied a multidimensional space\n",
    "    * Substantial trial to trial variability in neural response to visual stimuli\n",
    "        * Confirmed by elecrophyiology\n",
    "    * Simple nearest neighbor recorder able to identify stimulus with 75.5% accuracy\n",
    "        * Did not saturate with population = 10,000 suggesting more data may improve accuracy\n",
    "    * Responses only partially captured using linear and nonlinear models\n",
    "        * Consistent with prior cortex studies\n",
    "    * **Both receptive field models only explained a minor portion of stimulus related variance**\n",
    "    * Overlap between receptive fields of simulataneously recorded neurons, but the sizes and shapes were highly diverse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[**Mouse V1 population correlates of visual detection rely on heterogeneity within neuronal response patterns**](https://elifesciences.org/articles/10163) - Montijin et al., 2015 \n",
    "* Difference between sight and perception\n",
    "    * Daydreaming with your eyes open\n",
    "* Perceived object vs something seen, but not perceived\n",
    "    * Small differences using relatively coarse techniques\n",
    "    * Only looking at average activity of a brain region or group of neurons suggesting possible influence of coding\n",
    "* Visual perception proposed to arise frominteractions between stimulus-specific processing in V1 and neural activity in higher visual and frontoparietal areas\n",
    "    * Feed forward propagation and recurrent top-down feedback\n",
    "* Critical in decoding neural processing of visual stimuli is understanding how perceived and non-percieved images are processed differently\n",
    "* fMRI studies have proposed that neural activity in V1 doesn't correlate with activity in V1 (smh)\n",
    "* Noise correlation might be particularly important for sensory processins because the correlations can influcence amount of information whic can be extracted from population codes\n",
    "    * Correlations can be reduced during stimulus presentation and directed attention\n",
    "        * May aid disentangling stimulus info from noisy population responses\n",
    "* Assumption that neurons in distributed cortical architectures have relatively fixed roles in encoding visual features but modulate activation in temporally dynamic manner based on attentional needs \n",
    "* **Methods**\n",
    "    * **Are population activation patterns more similar across trials that repeat the same stimulus presentation when the stimulus is successfully detected?**\n",
    "    * Trained mice to lick reward spout when they perceived an image\n",
    "        * Lick within 3s\n",
    "    * Calcium imaging of ~100 neurons in V1 L2/3 w/ 2 photon\n",
    "    * Aim 1 - Examine whether visual detection correlates with mean visual response strength of V1 neurons\n",
    "* **Findings**\n",
    "    * Whether an image is perceived only weakly correlates to average activity\n",
    "    * Strength of responses of individual neurons more strongly correlated\n",
    "        * heterogeneous (non-uniform) set of neuronal responses occurred\n",
    "    * Diversity of responses could be used to measure how quickly mouse would perceive image  \n",
    "    * Visual stimulus detection does not correlate well with mean response strenght, but is significantly correlated with *population heterogeneity* \n",
    "    * Neuronal populations show consistencies in activation patterns across temporally spaced trials in association with hit responses but not when animal fails to report  stimulus\n",
    "    * Multidimensional structures in neuronal population responses provide information on visual detection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[**Synergistic population encoding and precise coordinated variability across interlaminar ensembles in the early visual system**](https://www.biorxiv.org/content/10.1101/812859v1) - Denman and Reid, 2019  \n",
    "* Prior evidence indicates visual info can be caputed by rate-based feature codes. \n",
    "* Other evidence suggest info may be extracted from absolute spike times\n",
    "* Stimulus info in spike timing/rate depends on tmeporal precision and shared variability of spikes within responses\n",
    "* Temporal precision of spike times realtive to stimulus presentation in single neurons has been measured across some anesthetized and some awake animals\n",
    "    * Individual neurons can be incredibly precise in anesthetized animals\n",
    "        * Spike timing-dependent plasticity\n",
    "* Variance could be intrinsically stochasitc or it could reflect variace in timed inputs that arent under experimental control\n",
    "* Visual repsonses of single neurons might be more precise if measured relative to each other or an internal framework\n",
    "* If and how latency variability is correlated across cells in the awake central visual system is unknown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[**A Tale of Two Retinal Domains: Near-Optimal Sampling of Achromatic Contrasts in Natural Scenes through Asymmetric Photoreceptor Distribution**](https://www.cell.com/action/showPdf?pii=S0896-6273%2813%2900861-1) - Baden et al., 2013"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[**Decoding Natural Sounds in Early Visual Cortex of Congenitally Blind Individuals**](https://www.sciencedirect.com/science/article/pii/S0960982220307582) - Vetter et al., 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[**How much color do we see in the blink of an eye?**](https://www.sciencedirect.com/science/article/abs/pii/S0010027720300871?via%3Dihub#bb0015) - Cohen and Rubenstein, 2020  \n",
    "*  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[**Kilosort: realtime spike-sorting for extracellular electrophysiology with hundreds of channels**](https://www.biorxiv.org/content/10.1101/061481v1) - Pachitariu et al., 2017\n",
    "* [Github link to Kilosort](https://github.com/MouseLand/Kilosort2)  \n",
    "* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[**Mouse color and wavelength-specific luminance contrast sensitivity are non-uniform across visual space**](https://elifesciences.org/articles/31209) - Denman et al., 2018\n",
    "*  Physiological color opponent signals in mouse retina, through the LGN, and possibly V1\n",
    "* Asymmetric and mixed expression of two opsins along dorso-ventral axis creating *opposing* gradients of wavelength band-specific responses\n",
    "    * Cone-driven color-opposonent signals and **any color sensitvity** can only exist in the opsin overalp of the central retina\n",
    "* Most cones express a combination of M and S opsins\n",
    "* Both rods and cones relatively uniform across azimuthal axis of retina\n",
    "* **However** short and middle opsin responses broadly overlap in higher visual areas\n",
    "    * Rod-cone antagonism can also create color opponency in some retinal ganglion cells\n",
    "    * Possibility that behaviorally relevant color info could be extracted more broadly across retinotopic space\n",
    "* Whether mice use color info to guide behavior remains an open question\n",
    "    * Evidence for color discrimination still unclear on how it depends on luminance, contrast, or retinotopic position  \n",
    "    * Unknown if gradients in opsin distribution lead to variations in behavioral luminance sensitivity across space\n",
    "    * **Non-uniformity would have a huge impact on population coding data collected in V1**\n",
    "\n",
    "\n",
    "* **Methods:**\n",
    "    * Go/no-go change detection task\n",
    "        * Mice indicate perceived change in stimulus by licking reward spout within 1s of change\n",
    "        * Subsequent licks allow reward consumption\n",
    "    * \"Ethologically-relevant mesopic luminance levels\" (10<sup>âˆ’3</sup> - 3 cd/m<sup>2</sup>, Wyszecki and Stiles, 1982)\n",
    "    * Measure detectability of luminance and color changes spearately across elevation\n",
    "    * Generate an estimate of wavelength-specific contrast sensitivity across visual space\n",
    "\n",
    "* Short and middle wavelength band specific contrast sensitivity\n",
    "    * Contrast sensitivity for UV highest in **upper** visual field\n",
    "        * More sensitive to decrements than increments in contrast\n",
    "    * Non-uniformity across elevation more pronounced for UV specificity than total luminance\n",
    "    * Constrast sensitivity for green highest in **lower** visual field \n",
    "    * Highest sensitivity to luminance change was in the upper visual field\n",
    "    * Sensitivity to increments in contrast similar for all elevations\n",
    "    * Sensitivity to decrements in contrast was higher than sensitivity to increments\n",
    "        * Most pronounced in the upper visual field\n",
    "* Determination of relative short and middle wavelength band contributions at several retinotopic locations and comparison with predicted cone weights\n",
    "\n",
    "* **Summary:**\n",
    "    * Mice are able to discriminate color, but only above the horizon\n",
    "    * Wavelength-specific luminance and color contrast sensitivity  dependent on retinotopic location\n",
    "        * Differences in sensitivity were less dramatic than expected from the cone opsin distribution\n",
    "    * Behavioral access to differential activation of rods and cones (?)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[**Spatial Organization of Chromatic Pathways in the Mouse Dorsal Lateral Geniculate Nucleus**](https://www.jneurosci.org/content/37/5/1102.long) - Denman et al., 2017  \n",
    "* Mouse Visual system is Dichromatic  \n",
    "    * Short Wavelength(S, Ultraviolet) and Medium Wavelength (M, Green) opsins  \n",
    "    * S opsin dominates ventral retina, M dominates dorsal  \n",
    "    * Central retina contains opsin transition zone  \n",
    "    * Many M cones express both opsins  \n",
    "* Unclear how mouse visual system uses spectral sensitivity  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
